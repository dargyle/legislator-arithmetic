{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "differential-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from pyro.nn.auto_reg_nn import AutoRegressiveNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sapphire-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 10)\n",
    "arn = AutoRegressiveNN(10, [10], param_dims=[1])\n",
    "p = arn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "starting-apartment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "contained-windows",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "weighted-division",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015917</td>\n",
       "      <td>0.248514</td>\n",
       "      <td>-0.316904</td>\n",
       "      <td>-0.269666</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.108173</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.245178</td>\n",
       "      <td>0.015393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083069</td>\n",
       "      <td>0.337242</td>\n",
       "      <td>-0.365985</td>\n",
       "      <td>-0.164847</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.101057</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.188734</td>\n",
       "      <td>0.020842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097815</td>\n",
       "      <td>0.109435</td>\n",
       "      <td>-0.213368</td>\n",
       "      <td>-0.063219</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.021830</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.100119</td>\n",
       "      <td>0.041720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.267006</td>\n",
       "      <td>-0.437566</td>\n",
       "      <td>-0.332692</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.184909</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.217232</td>\n",
       "      <td>-0.021448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040029</td>\n",
       "      <td>0.209996</td>\n",
       "      <td>-0.266993</td>\n",
       "      <td>-0.047321</td>\n",
       "      <td>-0.260747</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.039653</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.156152</td>\n",
       "      <td>0.031274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.038624</td>\n",
       "      <td>0.204284</td>\n",
       "      <td>-0.192796</td>\n",
       "      <td>-0.267576</td>\n",
       "      <td>-0.259723</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.057952</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.282300</td>\n",
       "      <td>0.042393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.254068</td>\n",
       "      <td>-0.260217</td>\n",
       "      <td>-0.047348</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.043020</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.156761</td>\n",
       "      <td>0.044363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.027880</td>\n",
       "      <td>0.170119</td>\n",
       "      <td>-0.266572</td>\n",
       "      <td>-0.060666</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.016451</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.105610</td>\n",
       "      <td>0.044363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.297084</td>\n",
       "      <td>-0.303005</td>\n",
       "      <td>-0.201916</td>\n",
       "      <td>-0.259105</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.085469</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.257904</td>\n",
       "      <td>0.030525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.309531</td>\n",
       "      <td>-0.276963</td>\n",
       "      <td>-0.101251</td>\n",
       "      <td>-0.259568</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>-0.013779</td>\n",
       "      <td>-0.130347</td>\n",
       "      <td>-0.087570</td>\n",
       "      <td>0.042887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.015917  0.248514 -0.316904 -0.269666 -0.259105  0.169129 -0.108173   \n",
       "1   0.083069  0.337242 -0.365985 -0.164847 -0.259105  0.169129 -0.101057   \n",
       "2  -0.097815  0.109435 -0.213368 -0.063219 -0.259105  0.169129 -0.021830   \n",
       "3   0.027545  0.267006 -0.437566 -0.332692 -0.259105  0.169129 -0.184909   \n",
       "4  -0.040029  0.209996 -0.266993 -0.047321 -0.260747  0.169129 -0.039653   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.038624  0.204284 -0.192796 -0.267576 -0.259723  0.169129 -0.057952   \n",
       "96  0.000190  0.254068 -0.260217 -0.047348 -0.259105  0.169129 -0.043020   \n",
       "97 -0.027880  0.170119 -0.266572 -0.060666 -0.259105  0.169129 -0.016451   \n",
       "98  0.007624  0.297084 -0.303005 -0.201916 -0.259105  0.169129 -0.085469   \n",
       "99  0.002991  0.309531 -0.276963 -0.101251 -0.259568  0.169129 -0.013779   \n",
       "\n",
       "           7         8         9  \n",
       "0  -0.130347 -0.245178  0.015393  \n",
       "1  -0.130347 -0.188734  0.020842  \n",
       "2  -0.130347 -0.100119  0.041720  \n",
       "3  -0.130347 -0.217232 -0.021448  \n",
       "4  -0.130347 -0.156152  0.031274  \n",
       "..       ...       ...       ...  \n",
       "95 -0.130347 -0.282300  0.042393  \n",
       "96 -0.130347 -0.156761  0.044363  \n",
       "97 -0.130347 -0.105610  0.044363  \n",
       "98 -0.130347 -0.257904  0.030525  \n",
       "99 -0.130347 -0.087570  0.042887  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(p.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "applicable-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR2_full(nn.Module): #returns entire sequence\n",
    "    def __init__(self, data, p=2, init=None):\n",
    "        super(AR2_full, self).__init__()\n",
    "        self.p = p\n",
    "        self.data = data.detach()\n",
    "        self.data.requires_grad = False\n",
    "        self.init = nn.Parameter(self.data[0:self.p])\n",
    "        self.phi = nn.Parameter(to.randn(self.p)/ 10)\n",
    "        self.const = nn.Parameter(to.randn(1)/10)\n",
    "        self.var = nn.Parameter(to.tensor([1.]))\n",
    "        self.lastx = to.randn(p)/10.\n",
    "        N,p= self.data.shape[0], self.p\n",
    "    \n",
    "    def set_lastx(self,data): #used for initialization only\n",
    "        with to.no_grad():\n",
    "            for i in range(data.shape[0]):\n",
    "                self.lastx[i] = data[i]\n",
    "            \n",
    "    def append_lastx(self,y_new):\n",
    "        with to.no_grad():\n",
    "            for i in range(self.lastx.shape[0]-1):\n",
    "                self.lastx[i+1] = self.lastx[i]\n",
    "            self.lastx[0] = y_new\n",
    "    \n",
    "    def loglikelihood(self):\n",
    "        N,p = self.data.shape[0],self.p\n",
    "        logprob = to.Tensor([0.])\n",
    "        logprob.requires_grad=True\n",
    "        for i in range(p,N,1):\n",
    "            data = self.data[i-p:i]\n",
    "            loc = self.phi @ data + self.const\n",
    "            l = to.distributions.Normal(loc=loc,scale=self.var)\n",
    "            logprob = logprob + l.log_prob(self.data[i])\n",
    "        return logprob\n",
    "    \n",
    "    def forward(self):\n",
    "        noise = to.distributions.Normal(loc=0,scale=self.var).sample()\n",
    "        lastx = to.stack(list(self.lastx)).detach()\n",
    "        y = (self.phi @ lastx) + noise + self.const\n",
    "        self.append_lastx(y.detach())\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "spare-harvest",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gendata3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-959f944b19d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAR2_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgendata3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gendata3' is not defined"
     ]
    }
   ],
   "source": [
    "ar2 = AR2_full(gendata3,p=2)\n",
    "optim = to.optim.SGD(lr=1e-4,params=ar2.parameters())\n",
    "losses = []\n",
    "\n",
    "n_steps = 100\n",
    "for step in range(n_steps):\n",
    "    optim.zero_grad()\n",
    "    with to.no_grad(): #reset initial values\n",
    "        ar2.set_lastx(ar2.init)\n",
    "    loss = -1*ar2.loglikelihood()\n",
    "    loss.backward()\n",
    "    losses.append(loss.detach().numpy())\n",
    "    optim.step()\n",
    "    cur_step = cur_step + 1 if cur_step < 3 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aggregate-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = nn.Linear(1, 1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "plain-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "gross-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0284],\n",
       "        [ 0.9978],\n",
       "        [-1.0957],\n",
       "        [-0.5926],\n",
       "        [-0.8894],\n",
       "        [ 0.4381],\n",
       "        [ 0.9547],\n",
       "        [-1.0362],\n",
       "        [ 0.3439],\n",
       "        [ 1.8091]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "purple-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0367],\n",
       "        [ 1.2887],\n",
       "        [-1.4152],\n",
       "        [-0.7654],\n",
       "        [-1.1488],\n",
       "        [ 0.5658],\n",
       "        [ 1.2331],\n",
       "        [-1.3384],\n",
       "        [ 0.4442],\n",
       "        [ 2.3365]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "productive-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.7743]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for jj in thing.parameters():\n",
    "    print(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FN-Root",
   "language": "python",
   "name": "fn-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
